# Relatório de Estudos

**Nome do Estagiário:** Gustavo Monteiro Gomes Pires 
**Data:** 07/08/2024

**Módulos/Etapas Feitas:**  
1. Bases analítcas
2. Bases Transacionais
3. Big Query
4. Python
5. Apache Spark

## Resumo dos módulos 

**Bases Analíticas**

São estruturas para analisar e criar insights de dados, as consultas sofrem constantes mudanças para executar dados complexos e pesados da maneira mais rápida e eficiente, permite flexibilidade e escalabilidade para diferentes volumes de dados, integração de dados de várias fontes para uma visão holística, e ferramentas avançadas para análises, visualização e machine learning. No entanto, elas também apresentam desafios, incluindo complexidade de implementação e manutenção, custos elevados dependendo da ferramenta, dificuldades no gerenciamento da qualidade e segurança dos dados, e a necessidade de ajustes frequentes na infraestrutura para lidar com o crescimento contínuo dos dados.

Para gerenciar esses dados, utilizam-se Data Lakes, Marts e Warehouses de forma complementar. O Data Lake armazena dados brutos de diversas fontes, sem estrutura definida, os Data Marts são repositorios menores que atendem analíses específicas, variando por exemlpo, de departamento para departamento enquanto, o Data Warehouse contém dados processados e estruturados para consultas e análises eficientes. Isso permite flexibilidade e escalabilidade no armazenamento inicial dos dados no Data Lake, e estrutura e desempenho otimizados para análise de negócios no Data Warehouse.

**Bases Transacionais**

São sistemas de gerenciamento e processamento de transações de dados em tempo real (OLTP - Online Transaction Processing), realiza operações de criação, leitura, atualização e exclusão de dados (CRUD) de maneira rápida e eficiente, suportam grande números de usuários simultâneos, mas mantendo a integridade dos dados e a baixa latência.

```
Propriedades ACID
Atomicidade: Assegura que todas as operações dentro de uma transação sejam concluídas com sucesso; se uma parte da transação falhar, toda a transação falha e o sistema retorna ao estado anterior.
Consistência: Garante que uma transação leve o banco de dados de um estado válido para outro estado válido, mantendo a integridade dos dados.
Isolamento: Garante que as transações sejam isoladas umas das outras, prevenindo interferências entre transações simultâneas.
Durabilidade: Assegura que, uma vez que uma transação é confirmada, as mudanças persistem mesmo em caso de falha do sistema.
```

**Big Query**

O Google BigQuery é um serviço de data warehouse totalmente gerenciado e altamente escalável, projetado para executar consultas SQL rápidas e eficazes em grandes volumes de dados. Ele oferece escalabilidade para lidar com simples consultas ou até com petabytes de dados, suporte para análise em tempo real, integração com ferramentas de BI (Business Intelligence) e recursos de machine learning integrados.

**Linguagens e Frameworks**

**Python** é uma linguagem de programação que foi criada com objetivo de ser facilmente lida e escrita, pode ser usada para vários fins, como desenvolvimento web, análise de dados, IA e até machine learning.

**Apache Spark** é um framework de processamento de dados em grande escala, seu diferencial é processar os dados em memória, resultando num desempenho muito rápido. Utilizando o *PySpark* como interface podemos utilizar a sintaxe e as bibliotecas da linguagem Python para  monitorar dados de sensores em tempo real para manutenção preditiva e monitoramento de condições ou grandes volumes de logs e detecção de anomalias, usar algoritmos de machine learning para recomendar produtos através do histórico do usuário.

**Apache Beam**

É um modelo unificado para processamento de dados em lote e streaming, permite definir e executar uma pipeline consistente em diferentes plataformas e linguagens, utilizado em ETL, analisar e responder dados de streaming em tempo real e realizar cálculos complexos.



## Links de Laboratórios (se houver)

- [Google Colab 1/Notion 1](URL_do_Lab_1)
- [Google Colab 2/Notion 2](URL_do_Lab_2)
- ...

**Recursos Utilizados:**  
- Youtube
- Google Big Query
- Google Cloud Skills Boost


**Principais comandos: (se aplicável)**  
- [Comando 1]
- [Comando 2]
- [Comando 3]
- ...

**Desafios Encontrados:**  
Descreva quaisquer desafios ou obstáculos que você encontrou durante a trilha de aprendizagem e como você os superou ou planeja superá-los.

**Feedback e Ajustes:**  
Como uma melhoria futura, era interessante adicionar exemplos práticos do uso dessas tecnologias e talvez até atividades(Projeto/Quiz) para melhor entendimento do assunto.

**Próximos Passos:**  
Continuar aprofundando sobre os temas na trilha de conhecimento e realizar projetos para melhor compreensão do assunto.